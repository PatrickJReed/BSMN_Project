{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "##Path to Data\n",
    "basepath = \"/home/ubuntu/efs/SLAV_Data/TrainingData/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_1_input (InputLayer)     (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 64, 3)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 64, 64, 3)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 64, 64, 3)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 64, 64, 3)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4)            2836516     lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Concatenate)      (None, 4)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "                                                                 sequential_1[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,836,516\n",
      "Trainable params: 2,836,132\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "Found 5393 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "#Test basic model on SLAV\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "K.set_session(sess)\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 64,64\n",
    "\n",
    "train_data_dir = os.path.join(basepath, 'Train')\n",
    "validation_data_dir = os.path.join(basepath, 'Validate')\n",
    "nb_train_samples = 5393\n",
    "nb_validation_samples = 400\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model = multi_gpu_model(model,4)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(64, 64),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(64, 64),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // (batch_size * 4),\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // (batch_size * 4), verbose=1)\n",
    "\n",
    "model.save_weights('first_try_SLAV.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSeg = parallel_model.evaluate_generator(validation_generator,10000, workers=8, use_multiprocessing=True)\n",
    "print(\"Accuracy = \",scoreSeg[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = parallel_model.predict_generator(validation_generator,10000, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MNIST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "model = load_model('MNIST_model.h5')\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
