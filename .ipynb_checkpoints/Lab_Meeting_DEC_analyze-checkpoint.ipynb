{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble, discriminant_analysis, random_projection)\n",
    "from sklearn.decomposition import (PCA, RandomizedPCA)\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "from keras_dec import DeepEmbeddingClustering\n",
    "if (sys.version[0] == 2):\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140694, 196608)\n",
      "-70.6948\n",
      "70.69768\n"
     ]
    }
   ],
   "source": [
    "basepath = \"/home/ubuntu/efs/SLAV_Data/SML/\"\n",
    "os.chdir(os.path.join(basepath))\n",
    "X = np.load('SML_Data.npzdBcMZU-numpy.npy')\n",
    "X2 = X.reshape((X.shape[0],-1))\n",
    "print X2.shape\n",
    "X3 = X2[:5000,:].astype(np.float32)\n",
    "std_scale = preprocessing.StandardScaler().fit(X3)\n",
    "X3 = std_scale.transform(X3)\n",
    "print X3.min()\n",
    "print X3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layerwise pretrain\n",
      "Epoch 1/26\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 1.4488\n",
      "Epoch 2/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.1969\n",
      "Epoch 3/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.1357\n",
      "Epoch 4/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.1096\n",
      "Epoch 5/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0944\n",
      "Epoch 6/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0852\n",
      "Epoch 7/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0784\n",
      "Epoch 8/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0728\n",
      "Epoch 9/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0687\n",
      "Epoch 10/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0649\n",
      "Epoch 11/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0615\n",
      "Epoch 12/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0592\n",
      "Epoch 13/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0570\n",
      "Epoch 14/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0550\n",
      "Epoch 15/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0533\n",
      "Epoch 16/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0517\n",
      "Epoch 17/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0505\n",
      "Epoch 18/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0489\n",
      "Epoch 19/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0473\n",
      "Epoch 20/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0465\n",
      "Epoch 21/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0456\n",
      "Epoch 22/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0443\n",
      "Epoch 23/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0434\n",
      "Epoch 24/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0429\n",
      "Epoch 25/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0426\n",
      "Epoch 26/26\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 1.0411\n",
      "Epoch 1/26\n",
      "5000/5000 [==============================] - 0s 16us/step - loss: 0.7857\n",
      "Epoch 2/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.3605\n",
      "Epoch 3/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.3128\n",
      "Epoch 4/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.3050\n",
      "Epoch 5/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.3018\n",
      "Epoch 6/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2999\n",
      "Epoch 7/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2984\n",
      "Epoch 8/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2965\n",
      "Epoch 9/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2943\n",
      "Epoch 10/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2937\n",
      "Epoch 11/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2928\n",
      "Epoch 12/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2927\n",
      "Epoch 13/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2918\n",
      "Epoch 14/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2918\n",
      "Epoch 15/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2906\n",
      "Epoch 16/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2893\n",
      "Epoch 17/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2884\n",
      "Epoch 18/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2876\n",
      "Epoch 19/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2850\n",
      "Epoch 20/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2820\n",
      "Epoch 21/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2809\n",
      "Epoch 22/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2799\n",
      "Epoch 23/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2776\n",
      "Epoch 24/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2766\n",
      "Epoch 25/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2761\n",
      "Epoch 26/26\n",
      "5000/5000 [==============================] - 0s 10us/step - loss: 0.2748\n",
      "Epoch 1/26\n",
      "5000/5000 [==============================] - 0s 18us/step - loss: 0.1245\n",
      "Epoch 2/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0399\n",
      "Epoch 3/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0253\n",
      "Epoch 4/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0216\n",
      "Epoch 5/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0204\n",
      "Epoch 6/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0196\n",
      "Epoch 7/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0191\n",
      "Epoch 8/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0189\n",
      "Epoch 9/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0189\n",
      "Epoch 10/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0186\n",
      "Epoch 11/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0174\n",
      "Epoch 12/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0169\n",
      "Epoch 13/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0167\n",
      "Epoch 14/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0167\n",
      "Epoch 15/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0164\n",
      "Epoch 16/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0163\n",
      "Epoch 17/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0162\n",
      "Epoch 18/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0162\n",
      "Epoch 19/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0161\n",
      "Epoch 20/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0161\n",
      "Epoch 21/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0161\n",
      "Epoch 22/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0160\n",
      "Epoch 23/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0160\n",
      "Epoch 24/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0159\n",
      "Epoch 25/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0155\n",
      "Epoch 26/26\n",
      "5000/5000 [==============================] - 0s 12us/step - loss: 0.0155\n",
      "Epoch 1/26\n",
      "5000/5000 [==============================] - 0s 20us/step - loss: 0.0169\n",
      "Epoch 2/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0164\n",
      "Epoch 3/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0157\n",
      "Epoch 4/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0144\n",
      "Epoch 5/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0123\n",
      "Epoch 6/26\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 0.0093\n",
      "Epoch 7/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0066\n",
      "Epoch 8/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0052\n",
      "Epoch 9/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0044\n",
      "Epoch 10/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0040\n",
      "Epoch 11/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0037\n",
      "Epoch 12/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0034\n",
      "Epoch 13/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0033\n",
      "Epoch 14/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0032\n",
      "Epoch 15/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0030\n",
      "Epoch 16/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0029\n",
      "Epoch 17/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0029\n",
      "Epoch 18/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0028\n",
      "Epoch 19/26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0027\n",
      "Epoch 20/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0026\n",
      "Epoch 21/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0024\n",
      "Epoch 22/26\n",
      "5000/5000 [==============================] - 0s 15us/step - loss: 0.0022\n",
      "Epoch 23/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0022\n",
      "Epoch 24/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0021\n",
      "Epoch 25/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0020\n",
      "Epoch 26/26\n",
      "5000/5000 [==============================] - 0s 14us/step - loss: 0.0020\n",
      "Finetuning autoencoder\n",
      "Epoch 1/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9390\n",
      "Epoch 2/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9383\n",
      "Epoch 3/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9378\n",
      "Epoch 4/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9376\n",
      "Epoch 5/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9374\n",
      "Epoch 6/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9373\n",
      "Epoch 7/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9372\n",
      "Epoch 8/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9371\n",
      "Epoch 9/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9370\n",
      "Epoch 10/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9370\n",
      "Epoch 11/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9369\n",
      "Epoch 12/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9369\n",
      "Epoch 13/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9369\n",
      "Epoch 14/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9368\n",
      "Epoch 15/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9368\n",
      "Epoch 16/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9368\n",
      "Epoch 17/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9367\n",
      "Epoch 18/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9367\n",
      "Epoch 19/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9367\n",
      "Epoch 20/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9367\n",
      "Epoch 21/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 22/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 23/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 24/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 25/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 26/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 27/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 28/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9366\n",
      "Epoch 29/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 30/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 31/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 32/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 33/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 34/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 35/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 36/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 37/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 38/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 39/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 40/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 41/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 42/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9365\n",
      "Epoch 43/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 44/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 45/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 46/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 47/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 48/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 49/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 50/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 51/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Epoch 52/52\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9364\n",
      "Initializing cluster centres with k-means.\n",
      "Initalized\n",
      "('Update interval', 19)\n",
      "('Save interval', 950)\n",
      "100.0% change in label assignment\n",
      "28.1% change in label assignment.484746Loss 1.638704Loss 1.270819Loss 1.313926Loss 1.390756Loss 1.039129Loss 1.023678Loss 0.956167Loss 1.520266Loss 0.937725Loss 1.550533Loss 1.594906Loss 1.432924Loss 1.259844Loss 1.124971Loss 0.987289\n",
      "29.74% change in label assignment.558129Loss 0.226282Loss 0.256200Loss 0.376191Loss 0.198275Loss 0.233363Loss 0.270381Loss 0.402343Loss 0.193458Loss 0.161681Loss 0.139093Loss 0.160991Loss 0.247355Loss 0.564272Loss 0.258472Loss 0.242456\n",
      "36.34% change in label assignment.437577Loss 0.621027Loss 0.491481Loss 0.339965Loss 0.222738Loss 0.219625Loss 0.188483Loss 0.310854Loss 0.499883Loss 0.285336Loss 0.243924Loss 0.313992Loss 0.265443Loss 0.368267Loss 0.214886Loss 0.248850\n",
      "35.44% change in label assignment.103445Loss 0.880805Loss 0.276228Loss 0.361020Loss 0.774450Loss 0.691705Loss 0.446074Loss 0.460022Loss 0.598044Loss 0.360086Loss 0.392987Loss 0.594085Loss 0.315897Loss 0.267752Loss 0.256615Loss 0.231616Loss 0.665282\n",
      "56.84% change in label assignment.888670Loss 0.594075Loss 0.405272Loss 0.281570Loss 0.246440Loss 0.237142Loss 0.241900Loss 0.373475Loss 0.587360Loss 0.325510Loss 0.271475Loss 0.276883Loss 0.270450Loss 0.373879Loss 0.315043Loss 0.431801\n",
      "51.78% change in label assignment.558944Loss 0.452498Loss 0.288267Loss 0.256343Loss 0.240169Loss 0.253956Loss 0.355352Loss 0.333907Loss 0.428202Loss 0.210986Loss 0.227081Loss 0.233476Loss 0.208013Loss 0.256846Loss 0.274827Loss 0.315340\n",
      "42.42% change in label assignment0.811035Loss 0.662491Loss 0.460059Loss 0.289728Loss 0.270273Loss 0.209308Loss 0.194107Loss 0.190586Loss 0.371142Loss 0.815259Loss 0.593044Loss 0.414309Loss 0.250996Loss 0.214418Loss 0.199684Loss 0.182287\n",
      "39.62% change in label assignment0.661085Loss 0.346970Loss 0.282251Loss 1.712807Loss 0.629255Loss 0.456210Loss 0.564064Loss 0.473435Loss 0.749525Loss 0.385670Loss 0.362919Loss 0.277002Loss 1.179870Loss 0.785050Loss 0.546030Loss 0.505643\n",
      "57.8% change in label assignment 0.103537Loss 0.182418Loss 0.341684Loss 0.388107Loss 0.198566Loss 0.182815Loss 0.192787Loss 0.165060Loss 0.186473Loss 0.206099Loss 0.231164Loss 0.278183Loss 0.346237Loss 0.182992Loss 0.191162Loss 0.194852\n",
      "61.02% change in label assignment0.621729Loss 0.252331Loss 0.261406Loss 0.239425Loss 0.198483Loss 0.276246Loss 0.272189Loss 0.337086Loss 0.292808Loss 0.313469Loss 0.210507Loss 0.205716Loss 0.161351Loss 0.182741Loss 0.253724Loss 0.373397\n",
      "65.86% change in label assignment0.508007Loss 0.393110Loss 0.253227Loss 0.300819Loss 0.286082Loss 0.237552Loss 0.236410Loss 0.324867Loss 0.374254Loss 0.274047Loss 0.286306Loss 0.244161Loss 0.222574Loss 0.298062Loss 0.377044Loss 0.283599\n",
      "65.56% change in label assignment0.526761Loss 0.304261Loss 0.308077Loss 0.288906Loss 0.251784Loss 0.270636Loss 0.266155Loss 0.260236Loss 0.291318Loss 0.276584Loss 0.297180Loss 0.289735Loss 0.214232Loss 0.263349Loss 0.325322Loss 0.339773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.3% change in label assignment 0.382613Loss 0.534288Loss 0.327627Loss 0.296870Loss 0.250542Loss 0.265528Loss 0.257051Loss 0.238008Loss 0.222756Loss 0.282956Loss 0.259973Loss 0.266956Loss 0.219097Loss 0.231235Loss 0.276333\n",
      "67.02% change in label assignment0.509831Loss 0.414160Loss 0.243032Loss 0.249193Loss 0.199871Loss 0.220267Loss 0.341311Loss 0.394734Loss 0.299051Loss 0.273017Loss 0.304611Loss 0.333817Loss 0.277832Loss 0.275839Loss 0.262453Loss 0.287260\n",
      "66.82% change in label assignment0.500363Loss 0.331478Loss 0.279237Loss 0.320101Loss 0.284614Loss 0.288804Loss 0.233361Loss 0.248929Loss 0.342614Loss 0.368091Loss 0.285751Loss 0.254930Loss 0.260389Loss 0.273875Loss 0.241099Loss 0.286249\n",
      "68.32% change in label assignment0.306620Loss 0.523117Loss 0.291355Loss 0.233401Loss 0.233644Loss 0.317840Loss 0.316699Loss 0.231133Loss 0.296131Loss 0.363726Loss 0.356231Loss 0.297528Loss 0.320450Loss 0.293170Loss 0.286279Loss 0.225670\n",
      "68.2% change in label assignment 0.409032Loss 0.371604Loss 0.378166Loss 0.328405Loss 0.317924Loss 0.298053Loss 0.267228Loss 0.199003Loss 0.237917Loss 0.234752Loss 0.259840Loss 0.304408Loss 0.360070Loss 0.324744Loss 0.275748Loss 0.265017\n",
      "66.58% change in label assignment0.524056Loss 0.398958Loss 0.395946Loss 0.316967Loss 0.378896Loss 0.408710Loss 0.285909Loss 0.279015Loss 0.246516Loss 0.253993Loss 0.309824Loss 0.471378Loss 0.298777Loss 0.249196Loss 0.394786Loss 0.332122\n",
      "Iteration 360, Loss 0.180341Loss 0.473804Loss 0.318429Loss 0.254654Loss 0.275855Loss 0.243034Loss 0.236190Loss 0.246698Loss 0.274452Loss 0.255319Loss 0.345996Loss 0.304213Loss 0.283256Loss 0.260528Loss 0.382235Loss 0.369079Loss 0.300995\r"
     ]
    }
   ],
   "source": [
    "X = None\n",
    "X2 = None\n",
    "c = DeepEmbeddingClustering(n_clusters=64, input_dim=196608)\n",
    "c.initialize(X3, finetune_iters=1000, layerwise_pretrain_iters=500)\n",
    "print(\"Initalized\")\n",
    "c.cluster(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X3[0].isfinite(X).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "basepath = \"/home/ubuntu/efs/SLAV_Data/TrainingData/_Test/testing/\"\n",
    "os.chdir(os.path.join(basepath))\n",
    "pkl_file = open('c58750.pkl', 'rb')\n",
    "data1 = pickle.load(pkl_file)\n",
    "pprint.pprint(data1)\n",
    "pkl_file.close()\n",
    "clust_2d = data1['clust_2d']\n",
    "z_2d = data1['z_2d']\n",
    "plt.scatter(clust_2d[:, 0], clust_2d[:, 1], alpha=0.8)\n",
    "plt.axis('equal');\n",
    "plt.show()\n",
    "plt.scatter(z_2d[:, 0], z_2d[:, 1], alpha=0.8)\n",
    "plt.axis('equal');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "basepath = \"/home/ubuntu/efs/SLAV_Data/TrainingData/_Test/testing/\"\n",
    "os.chdir(os.path.join(basepath))\n",
    "pkl_file = open('c70500.pkl', 'rb')\n",
    "data1 = pickle.load(pkl_file)\n",
    "pprint.pprint(data1)\n",
    "pkl_file.close()\n",
    "clust_2d = data1['clust_2d']\n",
    "z_2d = data1['z_2d']\n",
    "plt.scatter(clust_2d[:, 0], clust_2d[:, 1], alpha=0.8)\n",
    "plt.axis('equal');\n",
    "plt.show()\n",
    "plt.scatter(z_2d[:, 0], z_2d[:, 1], alpha=0.8)\n",
    "plt.axis('equal');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = c.encoder.predict(X)\n",
    "pca_2d = PCA(n_components=2).fit(z)\n",
    "z_2d = pca_2d.transform(z)\n",
    "z_2d.shape\n",
    "plt.scatter(z_2d[:, 0], z_2d[:, 1], alpha=0.8)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "n_sne = 10000\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=5000)\n",
    "tsne_pca_results = tsne.fit_transform(z)\n",
    "\n",
    "print 't-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_pca_results.shape\n",
    "plt.scatter(tsne_pca_results[:, 0], tsne_pca_results[:, 1], alpha=0.8)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"/home/ubuntu/efs/SLAV_Data/TrainingData/_Test/testing/\"\n",
    "os.chdir(os.path.join(basepath))\n",
    "data = np.load(\"_Test_sml.npz\")\n",
    "X = data['X']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df['label'] = y\n",
    "df['label'] = df['label'].apply(lambda i: str(i))\n",
    "\n",
    "X, y = None, None\n",
    "\n",
    "print 'Size of the dataframe: {}'.format(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndperm = np.random.permutation(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "\n",
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] \n",
    "df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print 'Explained variation per principal component: {}'.format(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ggplot import *\n",
    "\n",
    "chart = ggplot( df.loc[rndperm[:10000],:], aes(x='pca-one', y='pca-two', color='label') ) \\\n",
    "        + geom_point(size=75,alpha=0.8) \\\n",
    "        + ggtitle(\"First and Second Principal Components\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print 'Explained variation per principal component (PCA): {}'.format(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "print var1\n",
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.components_\n",
    "\n",
    "for i in  range ( 5 ):\n",
    "     for j in  range ( 10 ):\n",
    "        plt.sub .-- plot ( 5 , 10 , 1 + 10 * i + j)\n",
    "        plt.imshow (components [ 1 + 5 * i + j,:]. reshape ( 28 , 28 ))\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "n_sne = 10000\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=5000)\n",
    "tsne_pca_results = tsne.fit_transform(pca_result[rndperm[:n_sne]])\n",
    "\n",
    "print 't-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tsne = None\n",
    "df_tsne = df.loc[rndperm[:n_sne],:].copy()\n",
    "df_tsne['x-tsne-pca'] = tsne_pca_results[:,0]\n",
    "df_tsne['y-tsne-pca'] = tsne_pca_results[:,1]\n",
    "\n",
    "chart = ggplot( df_tsne, aes(x='x-tsne-pca', y='y-tsne-pca', color='label') ) \\\n",
    "        + geom_point(size=70,alpha=0.1) \\\n",
    "        + ggtitle(\"tSNE dimensions of Training Data(PCA_100)\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##t_SNE on image Matrix\n",
    "from sklearn.manifold import TSNE\n",
    "n_sne = 10000\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=5000)\n",
    "tsne_pca_results = tsne.fit_transform(df.loc[rndperm[:n_sne],:].values)\n",
    "\n",
    "print 't-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "n_sne = 10000\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=5000, n_jobs=64)\n",
    "Y = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"/home/ubuntu/efs/SLAV_Data/\"\n",
    "Bulk_1571_Cerebellum = \"1571_cereb_BT_40_L3\"\n",
    "Bulk_1571_Hippocampus = \"1571_hippo_BT_41_L3\"\n",
    "SC_1571_Hippo = [\"1571_hippo_SC_43_L3\",\"1571_hippo_SC_45_L3\",\"1571_hippo_SC_46_L3\",\"1571_hippo_SC_47_L3\",\"1571_hippo_SC_48_L3\",\"1571_hippo_SC_50_L3\",\"1571_hippo_SC_51_L3\",\"1571_hippo_SC_52_L3\",\"1571_hippo_SC_53_L3\",\"1571_hippo_SC_55_L3\",\"1571_hippo_SC_56_L3\",\"1571_hippo_SC_57_L3\",\"1571_hippo_SC_58_L3\",\"1571_hippo_SC_59_L3\",\"1571_hippo_SC_61_L3\",\"1571_hippo_SC_62_L3\",\"1571_hippo_SC_63_L3\",\"1571_hippo_SC_64_L3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Sets = []\n",
    "Data_Sets.append([SC_1571_Hippo,Bulk_1571_Hippocampus,Bulk_1571_Cerebellum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_sml = []\n",
    "metadata_sml = []\n",
    "#metadata2_sml = []\n",
    "\n",
    "for cell in SC_1571_Hippo:\n",
    "    print cell\n",
    "    #shutil.copy(os.path.join(basepath, \"final\", cell, cell+\"_Input_metadata.txt\"),os.path.join(basepath, diry, cell, cell+\"_Input_metadata.txt\"))\n",
    "    os.chdir(os.path.join(basepath, cell))\n",
    "## Load images and meta data from meta files\n",
    "    \n",
    "    with open(os.path.join(basepath, cell, cell+\"_Input_metadata.txt\")) as f:\n",
    "        for line in csv.reader(f, delimiter=\"\\t\"):\n",
    "            if os.path.isfile(line[3]):\n",
    "                readclass = line[5].split(\":\")[0]\n",
    "                peakclass_sml = line[5].split(\":\")[1]               \n",
    "                L1_class = line[5].split(\":\")[3]\n",
    "                #print os.path.join(basepath, diry, cell, line[3])\n",
    "                #if peakclass_sml == readclass:\n",
    "                class_sml = [readclass,L1_class]\n",
    "                filelist_sml.append(os.path.join(basepath, cell, line[3])) \n",
    "                metadata_sml.append(\"\".join(class_sml))\n",
    "                #metadata2_sml.append(\"\".join(L1_class))\n",
    "                \n",
    "os.chdir(os.path.join(basepath))\n",
    "X_sml = np.array([np.array(Image.open(fname).resize((256,256))) for fname in filelist_sml])\n",
    "Y_sml = np.array(metadata_sml).astype(str)\n",
    "print X_sml.shape\n",
    "print Y_sml.size\n",
    "print len(np.unique(Y_sml))\n",
    "n_classes_sml = Y_sml.size\n",
    "n_samples_sml = len(X_sml)\n",
    "np.savez(\"1571_Cells_sml\", X_sml=X_sml, Y_sml=Y_sml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
