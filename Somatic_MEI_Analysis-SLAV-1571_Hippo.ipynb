{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, gc\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble, discriminant_analysis, random_projection)\n",
    "from sklearn.decomposition import (PCA, RandomizedPCA)\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import pybedtools\n",
    "import pysam\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "##Path to Data\n",
    "basepath = \"/raid/LOG-G/SEQ_ARCHIVE/Patrick_Reed/BSMN/SLAV_Data/\" \n",
    "narrowpeak = \"-ready_peaks.narrowPeak\"\n",
    "peaks_merged = \"_peaksMerged.txt\"\n",
    "peaks_merged_bed = \"_peaksMerged.bed\"\n",
    "peaks_correct_bed = \"_peaksCorrect.bed\"\n",
    "peakregions_sml = \".peakregions_sml\"\n",
    "peakregions_lrg = \".peakregions_lrg\"\n",
    "peaks_correct_data = \"_peaksCorrect.data\"\n",
    "peaks_L1HS_bedgraph = \"_peaks_L1HS_mapped.bedgraph\"\n",
    "loci_sml = \".loci_sml\"\n",
    "loci_lrg = \".loci_lrg\"\n",
    "overlap = \"_overlap_\"\n",
    "overlap_sml = \"_overlap_sml_\"\n",
    "overlap_lrg = \"_overlap_lrg_\"\n",
    "L1HS_sam = \"-L1HS_mapped.sam\"\n",
    "bam = \"-ready.bam\"\n",
    "igv = \"-igv.xml\"\n",
    "bed = \".bed\"\n",
    "## rmask Paths \n",
    "L1HS = \"/raid/LOG-G/SEQ_ARCHIVE/Patrick_Reed/BSMN/rmask_L1HS_Final.bed\"\n",
    "L1PA2345 = \"/raid/LOG-G/SEQ_ARCHIVE/Patrick_Reed/BSMN/rmask_L1PA2345_Final.bed\"\n",
    "L1_Other = \"/raid/LOG-G/SEQ_ARCHIVE/Patrick_Reed/BSMN/rmask_L1_Other_Final.bed\"\n",
    "##IGV Template\n",
    "IGV = \"/raid/LOG-G/SEQ_ARCHIVE/Patrick_Reed/BSMN/igv-template4.xml\"\n",
    "\n",
    "Bulk_1571_Cerebellum = \"1571_cereb_BT_40_L3\"\n",
    "Bulk_1571_Hippocampus = \"1571_hippo_BT_41_L3\"\n",
    "SC_1571_Hippo = [\"1571_hippo_SC_43_L3\",\"1571_hippo_SC_45_L3\",\"1571_hippo_SC_46_L3\",\"1571_hippo_SC_47_L3\",\"1571_hippo_SC_48_L3\",\"1571_hippo_SC_50_L3\",\"1571_hippo_SC_51_L3\",\"1571_hippo_SC_52_L3\",\"1571_hippo_SC_53_L3\",\"1571_hippo_SC_55_L3\",\"1571_hippo_SC_56_L3\",\"1571_hippo_SC_57_L3\",\"1571_hippo_SC_58_L3\",\"1571_hippo_SC_59_L3\",\"1571_hippo_SC_61_L3\",\"1571_hippo_SC_62_L3\",\"1571_hippo_SC_63_L3\",\"1571_hippo_SC_64_L3\"]\n",
    "\n",
    "\n",
    "Data_Sets = []\n",
    "Data_Sets.append([SC_1571_Hippo,Bulk_1571_Hippocampus,Bulk_1571_Cerebellum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in Data_Sets:\n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        tree = ET.parse(IGV)\n",
    "        root = tree.getroot()\n",
    "        root[0][0].set('path', os.path.join(basepath,  cell, cell + peaks_L1HS_bedgraph)) #L1HS bedgraph\n",
    "        root[0][1].set('path', os.path.join(basepath,  cell, cell + bam)) #SC Path\n",
    "        root[0][3].set('path', os.path.join(basepath,  dset[1], dset[1] + bam)) #Bulk Brain Path\n",
    "        root[0][6].set('path', os.path.join(basepath,  dset[2], dset[2] + bam)) #Bulk Fib Path\n",
    "        root[1][0].set('id', os.path.join(basepath,  cell, cell + peaks_L1HS_bedgraph)) #L1HS bedgraph\n",
    "        root[2][0].set('id', os.path.join(basepath,  cell, cell + bam)) #SC Path\n",
    "        root[3][0].set('id', os.path.join(basepath,  dset[1], dset[1] + bam)) #Bulk Brain path\n",
    "        root[4][0].set('id', os.path.join(basepath,  dset[2], dset[2] + bam)) #Bulk Fib Path\n",
    "        tree.write(os.path.join(basepath,  cell, cell + igv))\n",
    "\n",
    "\n",
    "\n",
    "        myinput = open(os.path.join(basepath,  cell, cell + peaks_merged_bed))\n",
    "        myoutput = open(os.path.join(basepath,  cell, cell + peaks_correct_bed), 'w')\n",
    "        proc3 = Popen(['grep', '-E', '^(1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|X|Y)'], stdin=myinput, stdout=myoutput)\n",
    "        proc3.wait()    \n",
    "\n",
    "        myinput = os.path.join(basepath,  cell, cell + peaks_correct_bed)\n",
    "        myoutput1 = os.path.join(basepath,  cell, cell + peakregions_sml)\n",
    "        myoutput2 = os.path.join(basepath,  cell, cell + peakregions_lrg)\n",
    "        with open(myoutput1, 'w') as outfile:\n",
    "            with open(myinput, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for string in data:\n",
    "                    line = string.split('\\t')\n",
    "                    pos1 = int(line[1])\n",
    "                    pos2 = int(line[2])                  \n",
    "                    center = int((pos1 + pos2)/2)\n",
    "                    pad = 1000\n",
    "                    start = center - pad\n",
    "                    end = center + pad\n",
    "                    row = [line[0], str(start), str(end)]\n",
    "                    outfile.write('\\t'.join(row) + '\\n')\n",
    "        outfile.close()\n",
    "        infile.close()   \n",
    "        with open(myoutput2, 'w') as outfile:\n",
    "            with open(myinput, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for string in data:\n",
    "                    line = string.split('\\t')\n",
    "                    pos1 = int(line[1])\n",
    "                    pos2 = int(line[2])                  \n",
    "                    center = int((pos1 + pos2)/2)\n",
    "                    pad = 10000\n",
    "                    newstart = center - pad\n",
    "                    newend = center + pad\n",
    "                    row = [line[0], str(newstart), str(newend)]\n",
    "                    outfile.write('\\t'.join(row) + '\\n')\n",
    "        outfile.close()\n",
    "        infile.close()\n",
    " \n",
    "        #make and define L1HS sub sam file here and L1HS read names list\n",
    "        \n",
    "               \n",
    "        sc_file = pysam.AlignmentFile(os.path.join(basepath,  cell, cell + bam), \"rb\")\n",
    "        bb_file = pysam.AlignmentFile(os.path.join(basepath,  dset[1], dset[1] + bam), \"rb\")\n",
    "        bf_file = pysam.AlignmentFile(os.path.join(basepath,  dset[2], dset[2] + bam), \"rb\")\n",
    "        \n",
    "\n",
    "        myinput = os.path.join(basepath,  cell, cell + peaks_correct_bed)\n",
    "        myoutput = os.path.join(basepath,  cell, cell + peaks_correct_data)\n",
    "        \n",
    "        with open(myoutput, 'w') as outfile:\n",
    "            with open(myinput, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for region in data:\n",
    "                    sc_iter = sc_file.fetch(region.split('\\t')[0], int(region.split('\\t')[1]), int(region.split('\\t')[2]))\n",
    "                    bb_iter = bb_file.fetch(region.split('\\t')[0], int(region.split('\\t')[1]), int(region.split('\\t')[2]))\n",
    "                    bf_iter = bf_file.fetch(region.split('\\t')[0], int(region.split('\\t')[1]), int(region.split('\\t')[2]))\n",
    "                    sc_i = 0\n",
    "                    bb_i = 0\n",
    "                    bf_i = 0\n",
    "                    for x in sc_iter: sc_i+=1\n",
    "                    for y in bb_iter: bb_i+=1\n",
    "                    for z in bf_iter: bf_i+=1\n",
    "                    sc_count = 1 if sc_i > 0 else 0\n",
    "                    bb_count = 1 if bb_i > 0 else 0 \n",
    "                    bf_count = 1 if bf_i > 0 else 0 \n",
    "                    row = [str(region.strip().split('\\t')[0]), str(region.strip().split('\\t')[1]), str(region.strip().split('\\t')[2])]  \n",
    "                    outfile.write('\\t'.join(row) +'\\t'+str(sc_count)+str(bb_count)+str(bf_count)+'\\n')\n",
    "        \n",
    "        myinput = os.path.join(basepath,  cell, cell + peaks_correct_bed)\n",
    "        myoutput = open(os.path.join(basepath, cell, cell + L1HS_sam), 'w')\n",
    "        myoutput2 = os.path.join(basepath,  cell, cell + peaks_L1HS_bedgraph)\n",
    "        p1 = Popen(['samtools', 'view', '-h', '-L', L1HS, os.path.join(basepath,  cell, cell + bam)], stdout=myoutput)\n",
    "        p1.wait()\n",
    "        L1HS_file = pysam.AlignmentFile(os.path.join(basepath, cell, cell + L1HS_sam), 'r')\n",
    "        L1HS_read_names =[]\n",
    "        for read in L1HS_file.fetch(): \n",
    "            read_name = str(read).split('\\t')[0]\n",
    "            L1HS_read_names.append(read_name)\n",
    "        with open(myoutput2, 'w') as outfile:\n",
    "            with open(myinput, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for region in data:\n",
    "                    read_names = []\n",
    "                    for read in sc_file.fetch(region.split('\\t')[0], int(region.split('\\t')[1]), int(region.split('\\t')[2])):\n",
    "                        read_name = str(read).split('\\t')[0]\n",
    "                        read_names.append(read_name)\n",
    "                    L1HS_overlap = list(set(read_names) & set(L1HS_read_names))\n",
    "                    percent = (len(L1HS_overlap) / len(read_names))*100\n",
    "                    row = [str(region.strip().split('\\t')[0]), str(region.strip().split('\\t')[1]), str(region.strip().split('\\t')[2]), str(percent)]  \n",
    "                    outfile.write('\\t'.join(row)+'\\n')\n",
    "\n",
    "        filelist =[os.path.join(basepath,  cell, \"peaks.bed\"),os.path.join(basepath,  dset[1], \"peaks.bed\"),os.path.join(basepath,  dset[2], \"peaks.bed\"),L1HS,L1PA2345,L1_Other]\n",
    "        a = pybedtools.BedTool(os.path.join(basepath, cell, cell + peaks_correct_bed)) ##mergedpeaks2 overlap with loci window or with peak location???\n",
    "        count = 0\n",
    "        for fname in filelist:\n",
    "            b = pybedtools.BedTool(fname)\n",
    "            a_and_b = a.intersect(b, c=True)\n",
    "            myoutput = os.path.join(basepath,  cell, cell + overlap + str(count))\n",
    "            count +=1\n",
    "            a_and_b.saveas(myoutput)\n",
    "            myinput = open(myoutput)\n",
    "            newoutput = open(myoutput+\"_binary\", 'w')\n",
    "            #overlap_append\n",
    "            awk_cmd = r\"\"\"BEGIN { OFS = \"\\t\"; }; { if ($7 ~ \"^[1-9]*$\") $7 = \"1\"; else $7 = $7; }; 1\"\"\"\n",
    "            proc = Popen(['awk', awk_cmd], stdin=myinput, stdout=newoutput)  \n",
    "            proc.wait()\n",
    "            newoutput.flush()\n",
    "\n",
    "        a_sml = pybedtools.BedTool(os.path.join(basepath,  cell, cell + peakregions_sml)) ##mergedpeaks2 overlap with loci window or with peak location???\n",
    "        count = 0\n",
    "        for fname in filelist:\n",
    "            b = pybedtools.BedTool(fname)\n",
    "            a_and_b = a_sml.intersect(b, c=True)\n",
    "            myoutput = os.path.join(basepath,  cell, cell + overlap_sml + str(count))\n",
    "            count +=1\n",
    "            a_and_b.saveas(myoutput)\n",
    "            myinput = open(myoutput)\n",
    "            newoutput = open(myoutput+\"_binary\", 'w')\n",
    "            #overlap_append\n",
    "            awk_cmd = r\"\"\"BEGIN { OFS = \"\\t\"; }; { if ($4 >= 2) $4 = \"2\"; else $4 = $4; }; 1\"\"\"\n",
    "            proc = Popen(['awk', awk_cmd], stdin=myinput, stdout=newoutput)  \n",
    "            proc.wait()\n",
    "            newoutput.flush()\n",
    "\n",
    "        a_lrg = pybedtools.BedTool(os.path.join(basepath,  cell, cell + peakregions_lrg)) ##mergedpeaks2 overlap with loci window or with peak location???\n",
    "        count = 0\n",
    "        for fname in filelist:\n",
    "            b = pybedtools.BedTool(fname)\n",
    "            a_and_b = a_lrg.intersect(b, c=True)\n",
    "            myoutput = os.path.join(basepath,  cell, cell + overlap_lrg + str(count))\n",
    "            count +=1\n",
    "            a_and_b.saveas(myoutput)\n",
    "            myinput = open(myoutput)\n",
    "            newoutput = open(myoutput+\"_binary\", 'w')\n",
    "            #overlap_append\n",
    "            awk_cmd = r\"\"\"BEGIN { OFS = \"\\t\"; }; { if ($4 >= 2) $4 = \"2\"; else $4 = $4; }; 1\"\"\"\n",
    "            proc = Popen(['awk', awk_cmd], stdin=myinput, stdout=newoutput)  \n",
    "            proc.wait()\n",
    "            newoutput.flush()        \n",
    "\n",
    "        myinput_sml = os.path.join(basepath,  cell, cell + peakregions_sml)\n",
    "        myoutput_sml = os.path.join(basepath,  cell, cell + loci_sml)\n",
    "        with open(myoutput_sml, 'w') as outfile:\n",
    "            with open(myinput_sml, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for region in data:\n",
    "                    row = [str(region.strip().split('\\t')[0]),\":\",str(region.strip().split('\\t')[1]),\"-\",str(region.strip().split('\\t')[2])]  \n",
    "                    outfile.write(\"\".join(row)+'\\n')\n",
    "\n",
    "        myinput_lrg = os.path.join(basepath,  cell, cell + peakregions_lrg)\n",
    "        myoutput_lrg = os.path.join(basepath,  cell, cell + loci_lrg)\n",
    "        with open(myoutput_lrg, 'w') as outfile:\n",
    "            with open(myinput_lrg, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for region in data:\n",
    "                    row = [str(region.strip().split('\\t')[0]),\":\",str(region.strip().split('\\t')[1]),\"-\",str(region.strip().split('\\t')[2])]  \n",
    "                    outfile.write(\"\".join(row)+'\\n')    \n",
    "\n",
    "        Popen(['split', '-l', '100', '-d', os.path.join(basepath,  cell, cell + loci_sml), os.path.join(basepath,  cell, cell + \".split_loci_sml_\")]).wait()\n",
    "        Popen(['split', '-l', '100', '-d', os.path.join(basepath,  cell, cell + loci_lrg), os.path.join(basepath,  cell, cell + \".split_loci_lrg_\")]).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in Data_Sets:    \n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        os.chdir(os.path.join(basepath, cell))    \n",
    "        locifile = os.path.join(basepath, cell, cell + loci_sml)\n",
    "        worklist = glob.glob(\"*.split_loci_sml_*\")\n",
    "        batchsize = 10\n",
    "        print len(worklist)\n",
    "        for i in xrange(0, len(worklist), batchsize):\n",
    "            batch = worklist[i:i+batchsize]\n",
    "            print i\n",
    "            index = 1\n",
    "            procs = []\n",
    "            for file in batch:\n",
    "                print file\n",
    "                with open(os.path.join(basepath, cell, file)) as f0:\n",
    "                    first = f0.readline()# Read the first line.\n",
    "                    for last in f0: pass\n",
    "                    firstpic = cell+\"_sml\"+\"*\"+first.strip().split(':')[0]+\"_\"+first.strip().split(':')[1].split('-')[0]+\"_\"+first.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                    lastpic = cell+\"_sml\"+\"*\"+last.strip().split(':')[0]+\"_\"+last.strip().split(':')[1].split('-')[0]+\"_\"+last.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                    if not (glob.glob(os.path.join(basepath, cell, firstpic)) or glob.glob(os.path.join(basepath, cell, lastpic))): \n",
    "                        p = Popen(['igv_plotter', '-o', cell+\"_sml_\", '-L', file, '-v', '--max-panel-height', '1000', '--igv-jar-path', '/raid/LOG-G/SEQ_ARCHIVE/Patrick_Reed/BSMN/IGV_2.4-rc6/igv.jar', '-m', '6G', '-g', 'hg19', os.path.join(basepath, cell, cell + igv)])\n",
    "                        procs.append(p)\n",
    "            for pp in procs:\n",
    "                pp.wait()\n",
    "                #wait_timeout(pp,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in SingleCell_MDA:\n",
    "    print os.path.join(basepath, diry, cell)\n",
    "    os.chdir(os.path.join(basepath, diry, cell))    \n",
    "    locifile = os.path.join(basepath, diry, cell, cell + loci_lrg)\n",
    "    worklist = glob.glob(\"*.split_loci_lrg_*\")\n",
    "    batchsize = 10\n",
    "    print len(worklist)\n",
    "    for i in xrange(0, len(worklist), batchsize):\n",
    "        batch = worklist[i:i+batchsize]\n",
    "        print i\n",
    "        index = 1\n",
    "        procs = []\n",
    "        for file in batch:\n",
    "            print file\n",
    "            with open(os.path.join(basepath, diry, cell, file)) as f0:\n",
    "                first = f0.readline()# Read the first line.\n",
    "                for last in f0: pass\n",
    "                firstpic = cell+\"_lrg\"+\"*\"+first.strip().split(':')[0]+\"_\"+first.strip().split(':')[1].split('-')[0]+\"_\"+first.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                lastpic = cell+\"_lrg\"+\"*\"+last.strip().split(':')[0]+\"_\"+last.strip().split(':')[1].split('-')[0]+\"_\"+last.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                if not (glob.glob(os.path.join(basepath, diry, cell, firstpic)) or glob.glob(os.path.join(basepath, diry, cell, lastpic))): \n",
    "                    p = Popen(['igv_plotter', '-o', cell+\"_lrg_\", '-L', file, '-v', '--max-panel-height', '1000', '--igv-jar-path', '/raid/LOG-G/SEQ_ARCHIVE/Patrick_Reed/BSMN/Common_Experiment/IGV_2.4-rc6/igv.jar', '-m', '6G', '-g', 'hg19', os.path.join(basepath, diry, cell, cell + igv)])\n",
    "                    procs.append(p)\n",
    "        for pp in procs:\n",
    "            pp.wait()\n",
    "            #wait_timeout(pp,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in SingleCell_MDA:\n",
    "    print cell\n",
    "    os.chdir(os.path.join(basepath, diry, cell))\n",
    "    for file in glob.glob(\"*s*__*.png\"):\n",
    "        newfile = re.sub(\"_s\\d+__\", \"-\", file)\n",
    "        shutil.move(file, newfile)     \n",
    "    for file in glob.glob(\"*.png\"):\n",
    "        img = Image.open(file)\n",
    "        width = img.size[0]\n",
    "        height = img.size[1]\n",
    "        img2 = img.crop((70,130,width,height)).resize((200,500))\n",
    "        path = os.path.splitext(file)[0]\n",
    "        basename = os.path.basename(path)\n",
    "        outfile1 = basename + \"_crp.png\"\n",
    "        img2.save(outfile1)\n",
    "        #os.remove(file)\n",
    "    \n",
    "    mergedpeak_data = os.path.join(basepath, diry, cell, cell + peaks_correct_data)\n",
    "    regions_sml = os.path.join(basepath, diry, cell, cell + peakregions_sml)\n",
    "    regions_lrg = os.path.join(basepath, diry, cell, cell + peakregions_lrg)\n",
    "      \n",
    "    count=1\n",
    "    with open(mergedpeak_data) as r0,open(regions_sml) as r_sml,open(regions_lrg) as r_lrg:\n",
    "        Files= {}\n",
    "        for rr0,rr_sml,rr_lrg in zip(r0,r_sml,r_lrg):\n",
    "            line = rr0.strip().split('\\t')[0]+\"\\t\"+rr0.strip().split('\\t')[1]+\"\\t\"+rr0.strip().split('\\t')[2]+\"\\t\"+cell+\"_sml-\"+rr_sml.strip().split('\\t')[0]+\"_\"+rr_sml.strip().split('\\t')[1]+\"_\"+rr_sml.strip().split('\\t')[2]+\"_crp.png\"+\"\\t\"+cell+\"_lrg-\"+rr_lrg.strip().split('\\t')[0]+\"_\"+rr_lrg.strip().split('\\t')[1]+\"_\"+rr_lrg.strip().split('\\t')[2]+\"_crp.png\"+\"\\t\"+rr0.strip().split('\\t')[3]\n",
    "            Files[str(count)] = line\n",
    "            count+=1\n",
    "    \n",
    "    a = os.path.join(basepath, diry, cell, cell+\"_overlap_0_binary\")\n",
    "    b = os.path.join(basepath, diry, cell, cell+\"_overlap_1_binary\")\n",
    "    c = os.path.join(basepath, diry, cell, cell+\"_overlap_2_binary\")\n",
    "    d = os.path.join(basepath, diry, cell, cell+\"_overlap_3_binary\")\n",
    "    e = os.path.join(basepath, diry, cell, cell+\"_overlap_4_binary\")\n",
    "    f = os.path.join(basepath, diry, cell, cell+\"_overlap_5_binary\")\n",
    "    count=1\n",
    "    with open(a) as f1,open(b) as f2,open(c) as f3,open(d) as f4,open(e) as f5,open(f) as f6:\n",
    "        Peaks = {}\n",
    "        for aa,bb,cc,dd,ee,ff in zip(f1,f2,f3,f4,f5,f6):\n",
    "            line = aa.strip().split('\\t')[6]+bb.strip().split('\\t')[6]+cc.strip().split('\\t')[6]+\"\\t\"+dd.strip().split('\\t')[6]+ee.strip().split('\\t')[6]+ff.strip().split('\\t')[6]\n",
    "            Peaks[str(count)] = line\n",
    "            count+=1\n",
    "    \n",
    "    a_sml = os.path.join(basepath, diry, cell, cell+\"_overlap_sml_0_binary\")\n",
    "    b_sml = os.path.join(basepath, diry, cell, cell+\"_overlap_sml_1_binary\")\n",
    "    c_sml = os.path.join(basepath, diry, cell, cell+\"_overlap_sml_2_binary\")\n",
    "    d_sml = os.path.join(basepath, diry, cell, cell+\"_overlap_sml_3_binary\")\n",
    "    e_sml = os.path.join(basepath, diry, cell, cell+\"_overlap_sml_4_binary\")\n",
    "    f_sml = os.path.join(basepath, diry, cell, cell+\"_overlap_sml_5_binary\")\n",
    "    count=1\n",
    "    with open(a_sml) as f1,open(b_sml) as f2,open(c_sml) as f3,open(d_sml) as f4,open(e_sml) as f5,open(f_sml) as f6:\n",
    "        Small = {}\n",
    "        for aa,bb,cc,dd,ee,ff in zip(f1,f2,f3,f4,f5,f6):\n",
    "            line = aa.strip().split('\\t')[3]+bb.strip().split('\\t')[3]+cc.strip().split('\\t')[3]+\"\\t\"+dd.strip().split('\\t')[3]+ee.strip().split('\\t')[3]+ff.strip().split('\\t')[3]\n",
    "            Small[str(count)] = line\n",
    "            count+=1\n",
    "    \n",
    "    a_lrg = os.path.join(basepath, diry, cell, cell+\"_overlap_lrg_0_binary\")\n",
    "    b_lrg = os.path.join(basepath, diry, cell, cell+\"_overlap_lrg_1_binary\")\n",
    "    c_lrg = os.path.join(basepath, diry, cell, cell+\"_overlap_lrg_2_binary\")\n",
    "    d_lrg = os.path.join(basepath, diry, cell, cell+\"_overlap_lrg_3_binary\")\n",
    "    e_lrg = os.path.join(basepath, diry, cell, cell+\"_overlap_lrg_4_binary\")\n",
    "    f_lrg = os.path.join(basepath, diry, cell, cell+\"_overlap_lrg_5_binary\")\n",
    "    count=1\n",
    "    with open(a_lrg) as f1,open(b_lrg) as f2,open(c_lrg) as f3,open(d_lrg) as f4,open(e_lrg) as f5,open(f_lrg) as f6:\n",
    "        Large = {}\n",
    "        for aa,bb,cc,dd,ee,ff in zip(f1,f2,f3,f4,f5,f6):\n",
    "            line = aa.strip().split('\\t')[3]+bb.strip().split('\\t')[3]+cc.strip().split('\\t')[3]+\"\\t\"+dd.strip().split('\\t')[3]+ee.strip().split('\\t')[3]+ff.strip().split('\\t')[3]\n",
    "            Large[str(count)] = line\n",
    "            count+=1\n",
    "    \n",
    "    with open(os.path.join(basepath, diry, cell, cell+\"_Input_metadata.txt\"),\"w\") as f8:\n",
    "        for key in Files:\n",
    "            encoding = Files[key]+\":\"+Peaks[key].strip().split('\\t')[0]+\":\"+Large[key].strip().split('\\t')[0]+\":\"+Peaks[key].strip().split('\\t')[1]+\"\\n\"\n",
    "        #for (Fi, Fj),(Pi,Pj),(Si,Sj),(Li,Lj) in zip(Files.items(),Peaks.items(),Small.items(),Large.items()):\n",
    "            #encoding = Fj+\":\"+Pj.strip().split('\\t')[0]+\":\"+Sj.strip().split('\\t')[0]+\":\"+Lj.strip().split('\\t')[0]+\":\"+Pj.strip().split('\\t')[1]+\":\"+Sj.strip().split('\\t')[1]+\":\"+Lj.strip().split('\\t')[1]+\"\\n\"\n",
    "            f8.write(encoding)\n",
    "            \n",
    "#    with open(os.path.join(basepath, diry, cell, cell+\"_Input_metadata.txt\")) as f:\n",
    "#        for line in csv.reader(f, delimiter=\"\\t\"):\n",
    "#            if os.path.isfile(line[3]):\n",
    "#                filename = line[3]\n",
    "#                dst = line[5]\n",
    "#                if not os.path.exists(dst):\n",
    "#                    os.makedirs(os.path.join(basepath, diry, cell, dst))\n",
    "#                shutil.move(filename, os.path.join(basepath, diry, cell, dst))\n",
    "                       \n",
    "#    with open(os.path.join(basepath, diry, cell, cell+\"_Input_metadata.txt\")) as f:\n",
    "#        for line in csv.reader(f, delimiter=\"\\t\"):\n",
    "#            if os.path.isfile(line[4]):\n",
    "#                filename = line[4]\n",
    "#                dst = line[5]\n",
    "#                if not os.path.exists(dst):\n",
    "#                    os.makedirs(os.path.join(basepath, diry, cell, dst))\n",
    "#                shutil.move(filename, os.path.join(basepath, diry, cell, dst))                \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
