{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob, os, gc\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "##Path to Data\n",
    "basepath = \"/home/ubuntu/efs/mnist_png/mnist_png/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_1_input (InputLayer)     (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 28, 28, 1)    0           conv2d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 10)           595690      lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Concatenate)      (None, 10)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "                                                                 sequential_1[4][0]               \n",
      "                                                                 sequential_1[5][0]               \n",
      "                                                                 sequential_1[6][0]               \n",
      "                                                                 sequential_1[7][0]               \n",
      "                                                                 sequential_1[8][0]               \n",
      "==================================================================================================\n",
      "Total params: 595,690\n",
      "Trainable params: 595,306\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "Found 60000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 1013s 270ms/step - loss: 0.1488 - acc: 0.9545 - val_loss: 0.0652 - val_acc: 0.9804\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 1002s 267ms/step - loss: 0.0564 - acc: 0.9837 - val_loss: 0.0470 - val_acc: 0.9867\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 1013s 270ms/step - loss: 0.0416 - acc: 0.9878 - val_loss: 0.0286 - val_acc: 0.9917\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 1012s 270ms/step - loss: 0.0329 - acc: 0.9904 - val_loss: 0.0257 - val_acc: 0.9928\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 1007s 269ms/step - loss: 0.0266 - acc: 0.9921 - val_loss: 0.0255 - val_acc: 0.9927\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 1008s 269ms/step - loss: 0.0235 - acc: 0.9930 - val_loss: 0.0259 - val_acc: 0.9922\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 1007s 269ms/step - loss: 0.0203 - acc: 0.9938 - val_loss: 0.0240 - val_acc: 0.9931\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 1007s 269ms/step - loss: 0.0173 - acc: 0.9950 - val_loss: 0.0191 - val_acc: 0.9935\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 1005s 268ms/step - loss: 0.0154 - acc: 0.9957 - val_loss: 0.0262 - val_acc: 0.9934\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 1009s 269ms/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0270 - val_acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "#Test basic model on MNIST\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 28, 28\n",
    "\n",
    "train_data_dir = os.path.join(basepath, 'training')\n",
    "validation_data_dir = os.path.join(basepath, 'testing')\n",
    "nb_train_samples = 60000\n",
    "nb_validation_samples = 10000\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "parallel_model.summary()\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(28, 28),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(28, 28),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "parallel_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size, verbose=1)\n",
    "\n",
    "parallel_model.save_weights('first_try_mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy = ', 0.99299999999999999)\n"
     ]
    }
   ],
   "source": [
    "scoreSeg = parallel_model.evaluate_generator(validation_generator,10000, workers=8, use_multiprocessing=True)\n",
    "print(\"Accuracy = \",scoreSeg[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = parallel_model.predict_generator(validation_generator,10000, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MNIST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "model = load_model('MNIST_model.h5')\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
